{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SST","text":"<p>Welcome to the SST project! This site provides a quick overview and key links to help you explore the repository.</p>"},{"location":"#overview","title":"Overview","text":"<p>SST is a lightweight Python package and CLI that showcases machine learning predictions using Sea Surface Temperature (SST) and ENSO (Ni\u00f1o 3.4) data. It is designed for workshops and teaching environments, emphasizing testing, documentation, and continuous integration.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Project Repository</li> <li>Installation Guide</li> <li>Get Started</li> <li>API Reference</li> <li>Community Guidelines</li> </ul>"},{"location":"#stay-in-touch","title":"Stay in Touch","text":"<p>If you have questions or want to contribute, please open an issue or pull request on GitHub. We welcome ideas that improve clarity for learners and workshop participants.</p>"},{"location":"workshop_sst_demo/","title":"Notebook","text":"In\u00a0[1]: Copied! <pre># Environment checks\nimport sys\nfrom pathlib import Path\n\n# Get the repo root (parent of docs directory)\nroot = Path.cwd().parent\nprint(\"Python:\", sys.version)\nprint(\"Working directory:\", root)\nprint(\"Contents here:\", [p.name for p in root.iterdir()])\n</pre> # Environment checks import sys from pathlib import Path  # Get the repo root (parent of docs directory) root = Path.cwd().parent print(\"Python:\", sys.version) print(\"Working directory:\", root) print(\"Contents here:\", [p.name for p in root.iterdir()]) <pre>Python: 3.13.9 (main, Oct 17 2025, 11:40:15) [Clang 16.0.0 (clang-1600.0.26.6)]\nWorking directory: /Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst\nContents here: ['.flake8', 'artifacts', 'mkdocs.yml', 'LICENSE', '.pytest_cache', '.pre-commit-config.yaml', 'Dockerfile', 'CITATION.cff', '.ruff_cache', 'pyproject.toml', 'tests', 'docs', 'README.md', '.dockerignore', '.mypy_cache', '.gitignore', '.venv', 'scripts', '.github', 'site', '.git', 'data', 'src']\n</pre> In\u00a0[\u00a0]: Copied! <pre># Import the SST package modules\nfrom pathlib import Path\n\nfrom sst.io import load_enso, load_sst\nfrom sst.ml import predict_enso_from_sst\nfrom sst.plot import make_ml_prediction_plot\nfrom sst.transform import join_on_month, tidy\n\n# Set up paths\nroot = Path.cwd().parent\nsst_path = root / \"data\" / \"sst_sample.csv\"\nenso_path = root / \"data\" / \"nino34_sample.csv\"\nout_dir = root / \"artifacts\"\nout_dir.mkdir(parents=True, exist_ok=True)\nprint(f\"Output directory for model artifacts: {out_dir}\")\n</pre> # Import the SST package modules from pathlib import Path  from sst.io import load_enso, load_sst from sst.ml import predict_enso_from_sst from sst.plot import make_ml_prediction_plot from sst.transform import join_on_month, tidy  # Set up paths root = Path.cwd().parent sst_path = root / \"data\" / \"sst_sample.csv\" enso_path = root / \"data\" / \"nino34_sample.csv\" out_dir = root / \"artifacts\" out_dir.mkdir(parents=True, exist_ok=True) print(f\"Output directory for model artifacts: {out_dir}\") <pre>Output directory for model artifacts: /Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts\n</pre> In\u00a0[3]: Copied! <pre># Run the ML prediction workflow\nprint(\"Loading SST data...\")\nsst_df = tidy(load_sst(sst_path), date_col=\"date\", value_col=\"sst_c\", roll=12)\n\nprint(\"Loading ENSO data...\")\nenso_df = tidy(load_enso(enso_path), date_col=\"date\", value_col=\"nino34\", roll=12)\n\nprint(\"Joining datasets...\")\njoined = join_on_month(sst_df, enso_df, start=\"2000-01\")\n\nprint(\"Training ML model to predict ENSO from SST...\")\nresults = predict_enso_from_sst(\n    joined,\n    n_lags=3,\n    test_size=0.2,\n    random_state=42,\n    model_path=out_dir / \"model.joblib\",\n)\n\nprint(f\"Model performance: R\u00b2 = {results['r2_score']:.3f}, RMSE = {results['rmse']:.3f}\")\n</pre> # Run the ML prediction workflow print(\"Loading SST data...\") sst_df = tidy(load_sst(sst_path), date_col=\"date\", value_col=\"sst_c\", roll=12)  print(\"Loading ENSO data...\") enso_df = tidy(load_enso(enso_path), date_col=\"date\", value_col=\"nino34\", roll=12)  print(\"Joining datasets...\") joined = join_on_month(sst_df, enso_df, start=\"2000-01\")  print(\"Training ML model to predict ENSO from SST...\") results = predict_enso_from_sst(     joined,     n_lags=3,     test_size=0.2,     random_state=42,     model_path=out_dir / \"model.joblib\", )  print(f\"Model performance: R\u00b2 = {results['r2_score']:.3f}, RMSE = {results['rmse']:.3f}\") <pre>Loading SST data...\nLoading ENSO data...\nJoining datasets...\nTraining ML model to predict ENSO from SST...\nModel performance: R\u00b2 = 0.973, RMSE = 0.067\n</pre> In\u00a0[4]: Copied! <pre># Save predictions CSV\npredictions_path = out_dir / \"ml_predictions.csv\"\nresults[\"predictions\"].to_csv(predictions_path, index=False)\nprint(f\"\u2713 Wrote {predictions_path}\")\n\n# Save feature importance CSV\nimportance_path = out_dir / \"ml_feature_importance.csv\"\nresults[\"feature_importance\"].to_csv(importance_path, index=False)\nprint(f\"\u2713 Wrote {importance_path}\")\n\n# Save ML prediction plot\nfig = make_ml_prediction_plot(results)\nplot_path = out_dir / \"ml_predictions.png\"\nfig.savefig(plot_path, dpi=150, bbox_inches=\"tight\")\nprint(f\"\u2713 Wrote {plot_path}\")\n\nprint(f\"\\nArtifacts directory now contains:\\n{list(out_dir.iterdir())}\")\n</pre> # Save predictions CSV predictions_path = out_dir / \"ml_predictions.csv\" results[\"predictions\"].to_csv(predictions_path, index=False) print(f\"\u2713 Wrote {predictions_path}\")  # Save feature importance CSV importance_path = out_dir / \"ml_feature_importance.csv\" results[\"feature_importance\"].to_csv(importance_path, index=False) print(f\"\u2713 Wrote {importance_path}\")  # Save ML prediction plot fig = make_ml_prediction_plot(results) plot_path = out_dir / \"ml_predictions.png\" fig.savefig(plot_path, dpi=150, bbox_inches=\"tight\") print(f\"\u2713 Wrote {plot_path}\")  print(f\"\\nArtifacts directory now contains:\\n{list(out_dir.iterdir())}\") <pre>\u2713 Wrote /Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/ml_predictions.csv\n\u2713 Wrote /Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/ml_feature_importance.csv\n\u2713 Wrote /Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/ml_predictions.png\n\nArtifacts directory now contains:\n[PosixPath('/Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/summary.csv'), PosixPath('/Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/scatter_plot.png'), PosixPath('/Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/ml_predictions.csv'), PosixPath('/Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/model.joblib'), PosixPath('/Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/ml_feature_importance.csv'), PosixPath('/Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/ml_predictions.png'), PosixPath('/Users/ntebaldi/Documents/ai+science/workshops/workshop_1_github_actions/sst/artifacts/trends.png')]\n</pre> In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nroot = Path.cwd().parent\n\n\ndef load_time_series(path: Path) -&gt; pd.DataFrame:\n    \"\"\"Generic helper: parse first column as datetime and set as index.\"\"\"\n    df = pd.read_csv(path, parse_dates=[0])\n    df = df.set_index(df.columns[0]).sort_index()\n    return df\n\n\nsst_raw = load_time_series(root / \"data\" / \"sst_sample.csv\")\nenso_raw = load_time_series(root / \"data\" / \"nino34_sample.csv\")\n\ndisplay(\"SST sample:\")\ndisplay(sst_raw.head())\n\ndisplay(\"ENSO (Ni\u00f1o 3.4) sample:\")\ndisplay(enso_raw.head())\n</pre> from pathlib import Path  import matplotlib.pyplot as plt import pandas as pd  root = Path.cwd().parent   def load_time_series(path: Path) -&gt; pd.DataFrame:     \"\"\"Generic helper: parse first column as datetime and set as index.\"\"\"     df = pd.read_csv(path, parse_dates=[0])     df = df.set_index(df.columns[0]).sort_index()     return df   sst_raw = load_time_series(root / \"data\" / \"sst_sample.csv\") enso_raw = load_time_series(root / \"data\" / \"nino34_sample.csv\")  display(\"SST sample:\") display(sst_raw.head())  display(\"ENSO (Ni\u00f1o 3.4) sample:\") display(enso_raw.head()) <pre>'SST sample:'</pre> sst_c date 2000-01-01 20.000 2000-02-01 20.601 2000-03-01 21.041 2000-04-01 21.202 2000-05-01 21.043 <pre>'ENSO (Ni\u00f1o 3.4) sample:'</pre> nino34 date 2000-01-01 0.000 2000-02-01 0.145 2000-03-01 0.288 2000-04-01 0.424 2000-05-01 0.551 In\u00a0[6]: Copied! <pre>plt.figure(figsize=(10, 4))\nsst_raw.select_dtypes(\"number\").plot(ax=plt.gca())\nplt.title(\"Sea Surface Temperature sample (raw)\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"SST\")\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(10, 4))\nenso_raw.select_dtypes(\"number\").plot(ax=plt.gca())\nplt.title(\"Ni\u00f1o 3.4 ENSO index sample (raw)\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Index value\")\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(10, 4)) sst_raw.select_dtypes(\"number\").plot(ax=plt.gca()) plt.title(\"Sea Surface Temperature sample (raw)\") plt.xlabel(\"Date\") plt.ylabel(\"SST\") plt.tight_layout() plt.show()  plt.figure(figsize=(10, 4)) enso_raw.select_dtypes(\"number\").plot(ax=plt.gca()) plt.title(\"Ni\u00f1o 3.4 ENSO index sample (raw)\") plt.xlabel(\"Date\") plt.ylabel(\"Index value\") plt.tight_layout() plt.show() In\u00a0[7]: Copied! <pre>root = Path.cwd().parent\nartifacts = root / \"artifacts\"\n\n# Load the predictions CSV\npredictions_path = artifacts / \"ml_predictions.csv\"\npredictions = pd.read_csv(predictions_path, parse_dates=[\"date\"])\ndisplay(\"ML Predictions (first few rows):\")\ndisplay(predictions.head())\n</pre> root = Path.cwd().parent artifacts = root / \"artifacts\"  # Load the predictions CSV predictions_path = artifacts / \"ml_predictions.csv\" predictions = pd.read_csv(predictions_path, parse_dates=[\"date\"]) display(\"ML Predictions (first few rows):\") display(predictions.head()) <pre>'ML Predictions (first few rows):'</pre> date actual predicted residual 0 2008-01-01 0.457417 0.393394 0.064023 1 2008-02-01 0.528250 0.470006 0.058244 2 2008-03-01 0.586750 0.539111 0.047639 3 2008-04-01 0.631750 0.590405 0.041345 4 2008-05-01 0.662333 0.619597 0.042737 In\u00a0[8]: Copied! <pre># Load the feature importance CSV\nimportance_path = artifacts / \"ml_feature_importance.csv\"\nimportance = pd.read_csv(importance_path)\ndisplay(\"Feature Importance:\")\ndisplay(importance)\n</pre> # Load the feature importance CSV importance_path = artifacts / \"ml_feature_importance.csv\" importance = pd.read_csv(importance_path) display(\"Feature Importance:\") display(importance) <pre>'Feature Importance:'</pre> feature importance 0 nino34_roll_12_lag_1 0.977148 1 nino34_roll_12_lag_2 0.012872 2 nino34_roll_12_lag_3 0.003466 3 sst_c_roll_12_lag_3 0.002054 4 sst_c_roll_12_lag_1 0.001556 5 sst_c_roll_12 0.001527 6 sst_c_roll_12_lag_2 0.001377 In\u00a0[\u00a0]: Copied! <pre># Calculate R\u00b2 and RMSE from predictions for the plot title\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nr2 = r2_score(predictions[\"actual\"], predictions[\"predicted\"])\nrmse = np.sqrt(mean_squared_error(predictions[\"actual\"], predictions[\"predicted\"]))\n\n# Plot predictions over time\nplt.figure(figsize=(12, 5))\nplt.plot(predictions[\"date\"], predictions[\"actual\"], label=\"Actual\", alpha=0.7, linewidth=1.5)\nplt.plot(\n    predictions[\"date\"],\n    predictions[\"predicted\"],\n    label=\"Predicted\",\n    alpha=0.7,\n    linewidth=1.5,\n    linestyle=\"--\",\n)\nplt.xlabel(\"Date\")\nplt.ylabel(\"Ni\u00f1o 3.4 Index\")\nplt.title(f\"ML Predictions Over Time\\nR\u00b2 = {r2:.3f}, RMSE = {rmse:.3f}\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n</pre> # Calculate R\u00b2 and RMSE from predictions for the plot title import numpy as np from sklearn.metrics import mean_squared_error, r2_score  r2 = r2_score(predictions[\"actual\"], predictions[\"predicted\"]) rmse = np.sqrt(mean_squared_error(predictions[\"actual\"], predictions[\"predicted\"]))  # Plot predictions over time plt.figure(figsize=(12, 5)) plt.plot(predictions[\"date\"], predictions[\"actual\"], label=\"Actual\", alpha=0.7, linewidth=1.5) plt.plot(     predictions[\"date\"],     predictions[\"predicted\"],     label=\"Predicted\",     alpha=0.7,     linewidth=1.5,     linestyle=\"--\", ) plt.xlabel(\"Date\") plt.ylabel(\"Ni\u00f1o 3.4 Index\") plt.title(f\"ML Predictions Over Time\\nR\u00b2 = {r2:.3f}, RMSE = {rmse:.3f}\") plt.legend() plt.grid(True, alpha=0.3) plt.tight_layout() plt.show() In\u00a0[10]: Copied! <pre># Plot feature importance\nplt.figure(figsize=(10, 6))\ntop_features = importance.head(10)\nplt.barh(range(len(top_features)), top_features[\"importance\"], color=\"coral\", alpha=0.7)\nplt.yticks(range(len(top_features)), top_features[\"feature\"])\nplt.xlabel(\"Importance\")\nplt.title(\"Top 10 Feature Importance\")\nplt.gca().invert_yaxis()\nplt.grid(True, alpha=0.3, axis=\"x\")\nplt.tight_layout()\nplt.show()\n</pre> # Plot feature importance plt.figure(figsize=(10, 6)) top_features = importance.head(10) plt.barh(range(len(top_features)), top_features[\"importance\"], color=\"coral\", alpha=0.7) plt.yticks(range(len(top_features)), top_features[\"feature\"]) plt.xlabel(\"Importance\") plt.title(\"Top 10 Feature Importance\") plt.gca().invert_yaxis() plt.grid(True, alpha=0.3, axis=\"x\") plt.tight_layout() plt.show() In\u00a0[11]: Copied! <pre>root = Path.cwd().parent\nartifacts = root / \"artifacts\"\nml_plot_path = artifacts / \"ml_predictions.png\"\n\nif ml_plot_path.exists():\n    from IPython.display import Image, display\n\n    display(Image(filename=str(ml_plot_path)))\nelse:\n    print(\"No ml_predictions.png found in artifacts/\")\n</pre> root = Path.cwd().parent artifacts = root / \"artifacts\" ml_plot_path = artifacts / \"ml_predictions.png\"  if ml_plot_path.exists():     from IPython.display import Image, display      display(Image(filename=str(ml_plot_path))) else:     print(\"No ml_predictions.png found in artifacts/\") In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"workshop_sst_demo/#sst-demo-machine-learning-prediction-of-enso-from-sst","title":"SST Demo: Machine Learning Prediction of ENSO from SST\u00b6","text":"<p>This notebook demonstrates the SST package for machine learning prediction of ENSO from Sea Surface Temperature data. It will:</p> <ol> <li>Import the SST package modules.</li> <li>Run the ML prediction workflow using Python functions on the sample CSVs in <code>data/</code>.</li> <li>Load and explore the resulting ML artifacts (predictions, feature importance).</li> <li>Visualize the model performance and feature importance.</li> </ol> <p>Command to install dependencies:</p> <p><code>%pip install -e \".[dev]\"</code></p> <p>Tip: Make sure your working directory is the repo root (where <code>pyproject.toml</code> lives) when you install the dependencies to run. This uses the <code>pyproject.toml</code> in the repo and installs the <code>sst</code> CLI and Python package into your current environment.</p>"},{"location":"workshop_sst_demo/#1-run-the-ml-prediction-workflow-using-the-python-package","title":"1. Run the ML prediction workflow using the Python package\u00b6","text":"<p>This imports the SST package modules and runs the ML prediction workflow directly, writing artifacts into an <code>artifacts/</code> directory in the repo root.</p>"},{"location":"workshop_sst_demo/#2-explore-the-raw-sample-csvs","title":"2. Explore the raw sample CSVs\u00b6","text":"<p>We will load the SST and ENSO (Ni\u00f1o 3.4) sample CSVs from <code>data/</code> and inspect their structure. The code below intentionally treats the first column as a date/time index and any remaining columns as numeric values, so it will stay robust even if column names are tweaked in the future.</p>"},{"location":"workshop_sst_demo/#plot-the-raw-time-series","title":"Plot the raw time series\u00b6","text":"<p>We plot all numeric columns from each dataset against their datetime index.</p>"},{"location":"workshop_sst_demo/#3-inspect-and-explore-the-ml-prediction-artifacts","title":"3. Inspect and explore the ML prediction artifacts\u00b6","text":"<p>After running the ML prediction workflow, you should have several artifacts in <code>artifacts/</code>. We will load and explore the predictions and feature importance.</p>"},{"location":"workshop_sst_demo/#4-optional-display-the-generated-ml-prediction-figure","title":"4. (Optional) Display the generated ML prediction figure\u00b6","text":"<p>The workflow also writes a <code>ml_predictions.png</code> figure into <code>artifacts/</code>. If it exists, we can display it inline as a quick visual check.</p>"},{"location":"api/","title":"API Reference","text":"<p>Explore the auto-generated API documentation for SST ETL modules:</p> <ul> <li>CLI</li> <li>IO</li> <li>Transform</li> <li>Plot</li> </ul>"},{"location":"api/cli/","title":"<code>sst.cli</code>","text":"<p>Command-line interface for SST ML prediction workflow.</p>"},{"location":"api/cli/#sst.cli.predict","title":"<code>predict(sst=Path('data/sst_sample.csv'), enso=Path('data/nino34_sample.csv'), out_dir=Path('artifacts'), start='2000-01', n_lags=3, test_size=0.2, random_state=1, model_path=None)</code>","text":"<p>Run machine learning prediction of ENSO from SST.</p> <p>Parameters:</p> Name Type Description Default <code>sst</code> <code>Path</code> <p>Location of the SST CSV file to ingest.</p> <code>\"data/sst_sample.csv\"</code> <code>enso</code> <code>Path</code> <p>Location of the ENSO index CSV file to ingest.</p> <code>\"data/nino34_sample.csv\"</code> <code>out_dir</code> <code>Path</code> <p>Directory where generated ML artifacts are written.</p> <code>\"artifacts\"</code> <code>start</code> <code>str</code> <p>Earliest date to retain after joining the SST and ENSO data. Parsed to a timestamp via :func:<code>pandas.to_datetime</code>.</p> <code>\"2000-01\"</code> <code>n_lags</code> <code>int</code> <p>Number of lag features to include (previous months' values).</p> <code>3</code> <code>test_size</code> <code>float</code> <p>Proportion of data to use for testing (between 0 and 1).</p> <code>0.2</code> <code>random_state</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <code>model_path</code> <code>Path</code> <p>Path to save the trained model. If not provided, saves to <code>out_dir / \"model.joblib\"</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>Writes ML prediction plot, metrics, and model to <code>out_dir</code> and prints their locations.</p> Source code in <code>src/sst/cli.py</code> <pre><code>@app.command(\"predict\")\ndef predict(\n    sst: Path = Path(\"data/sst_sample.csv\"),\n    enso: Path = Path(\"data/nino34_sample.csv\"),\n    out_dir: Path = Path(\"artifacts\"),\n    start: str = \"2000-01\",\n    n_lags: int = 3,\n    test_size: float = 0.2,\n    random_state: int = 1,\n    model_path: Path | None = None,\n) -&gt; None:\n    \"\"\"Run machine learning prediction of ENSO from SST.\n\n    Parameters\n    ----------\n    sst : pathlib.Path, default=\"data/sst_sample.csv\"\n        Location of the SST CSV file to ingest.\n    enso : pathlib.Path, default=\"data/nino34_sample.csv\"\n        Location of the ENSO index CSV file to ingest.\n    out_dir : pathlib.Path, default=\"artifacts\"\n        Directory where generated ML artifacts are written.\n    start : str, default=\"2000-01\"\n        Earliest date to retain after joining the SST and ENSO data. Parsed\n        to a timestamp via :func:`pandas.to_datetime`.\n    n_lags : int, default=3\n        Number of lag features to include (previous months' values).\n    test_size : float, default=0.2\n        Proportion of data to use for testing (between 0 and 1).\n    random_state : int, default=42\n        Random seed for reproducibility.\n    model_path : pathlib.Path, optional\n        Path to save the trained model. If not provided, saves to\n        ``out_dir / \"model.joblib\"``.\n\n    Returns\n    -------\n    None\n        Writes ML prediction plot, metrics, and model to ``out_dir`` and prints\n        their locations.\n    \"\"\"\n\n    out_dir.mkdir(parents=True, exist_ok=True)\n    if model_path is None:  # default model path\n        model_path = out_dir / \"model.joblib\"\n\n    sst_df = tidy(load_sst(sst), date_col=\"date\", value_col=\"sst_c\", roll=12)\n    enso_df = tidy(load_enso(enso), date_col=\"date\", value_col=\"nino34\", roll=12)\n    joined = join_on_month(sst_df, enso_df, start=start)\n\n    logging.info(\"Training ML model to predict ENSO from SST...\")\n    results = predict_enso_from_sst(\n        joined,\n        n_lags=n_lags,\n        test_size=test_size,\n        random_state=random_state,\n        model_path=model_path,\n    )\n    logging.info(\n        f\"Model performance: R\u00b2 = {results['r2_score']: .3f}, RMSE = {results['rmse']: .3f}\"\n    )\n    logging.info(f\"Saved model to {model_path}\")\n\n    # Save predictions CSV\n    predictions_path = out_dir / \"ml_predictions.csv\"\n    predictions_value = results[\"predictions\"]\n    assert isinstance(predictions_value, pd.DataFrame), \"predictions must be a DataFrame\"\n    predictions_df: pd.DataFrame = predictions_value\n    predictions_df.to_csv(predictions_path, index=False)\n    logging.info(f\"Wrote {predictions_path}\")\n\n    # Save feature importance CSV\n    importance_path = out_dir / \"ml_feature_importance.csv\"\n    importance_value = results[\"feature_importance\"]\n    assert isinstance(importance_value, pd.DataFrame), \"feature_importance must be a DataFrame\"\n    importance_df: pd.DataFrame = importance_value\n    importance_df.to_csv(importance_path, index=False)\n    logging.info(f\"Wrote {importance_path}\")\n\n    # Save ML prediction plot\n    fig = make_ml_prediction_plot(results)\n    plot_path = out_dir / \"ml_predictions.png\"\n    fig.savefig(plot_path, dpi=150, bbox_inches=\"tight\")\n    logging.info(f\"Wrote {plot_path}\")\n</code></pre>"},{"location":"api/io/","title":"<code>sst.io</code>","text":"<p>IO helpers for loading SST and ENSO data sets.</p>"},{"location":"api/io/#sst.io.load_enso","title":"<code>load_enso(path)</code>","text":"<p>Load ENSO index observations from disk.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>File system location of a CSV file containing <code>date</code> and <code>nino34</code> columns.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Parsed ENSO index table with original column names and dtypes.</p> Source code in <code>src/sst/io.py</code> <pre><code>def load_enso(path: Path) -&gt; pd.DataFrame:\n    \"\"\"Load ENSO index observations from disk.\n\n    Parameters\n    ----------\n    path : pathlib.Path\n        File system location of a CSV file containing ``date`` and ``nino34``\n        columns.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Parsed ENSO index table with original column names and dtypes.\n    \"\"\"\n    return pd.read_csv(path)\n</code></pre>"},{"location":"api/io/#sst.io.load_sst","title":"<code>load_sst(path)</code>","text":"<p>Load sea surface temperature observations from disk.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>File system location of a CSV file containing <code>date</code> and <code>sst_c</code> columns.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Parsed SST table with original column names and dtypes.</p> Source code in <code>src/sst/io.py</code> <pre><code>def load_sst(path: Path) -&gt; pd.DataFrame:\n    \"\"\"Load sea surface temperature observations from disk.\n\n    Parameters\n    ----------\n    path : pathlib.Path\n        File system location of a CSV file containing ``date`` and ``sst_c``\n        columns.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Parsed SST table with original column names and dtypes.\n    \"\"\"\n    return pd.read_csv(path)\n</code></pre>"},{"location":"api/ml/","title":"<code>sst.ml</code>","text":"<p>Machine learning utilities for predicting SST-ENSO relationships.</p>"},{"location":"api/ml/#sst.ml.predict_enso_from_sst","title":"<code>predict_enso_from_sst(df, target_col='nino34_roll_12', feature_col='sst_c_roll_12', test_size=0.2, n_lags=3, random_state=42, model_path=None)</code>","text":"<p>Predict ENSO index from SST using a Random Forest model with lag features.</p> <p>This function creates a machine learning model to predict ENSO (Ni\u00f1o 3.4 index) from sea surface temperature data. It includes lag features to capture temporal dependencies in the time series.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Joined SST and ENSO tidy data that contains a <code>date</code> column along with at least one rolling SST column and one rolling ENSO column.</p> required <code>target_col</code> <code>str</code> <p>Name of the ENSO column to predict.</p> <code>\"nino34_roll_12\"</code> <code>feature_col</code> <code>str</code> <p>Name of the SST column to use as the primary feature.</p> <code>\"sst_c_roll_12\"</code> <code>test_size</code> <code>float</code> <p>Proportion of data to use for testing (between 0 and 1).</p> <code>0.2</code> <code>n_lags</code> <code>int</code> <p>Number of lag features to include (previous months' values).</p> <code>3</code> <code>random_state</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <code>model_path</code> <code>Path</code> <p>If provided, save the trained model to this path using joblib.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, float | DataFrame | RandomForestRegressor]</code> <p>Dictionary containing: - <code>r2_score</code>: R\u00b2 score on test set - <code>rmse</code>: Root mean squared error on test set - <code>predictions</code>: DataFrame with date, actual, and predicted values - <code>feature_importance</code>: DataFrame with feature importance scores - <code>model</code>: Trained RandomForestRegressor model (if model_path provided)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from sst.transform import join_on_month, tidy\n&gt;&gt;&gt; from sst.io import load_sst, load_enso\n&gt;&gt;&gt; sst_df = tidy(load_sst(\"data/sst_sample.csv\"), \"date\", \"sst_c\")\n&gt;&gt;&gt; enso_df = tidy(load_enso(\"data/nino34_sample.csv\"), \"date\", \"nino34\")\n&gt;&gt;&gt; joined = join_on_month(sst_df, enso_df)\n&gt;&gt;&gt; results = predict_enso_from_sst(joined, model_path=Path(\"model.joblib\"))\n&gt;&gt;&gt; \"r2_score\" in results\nTrue\n</code></pre> Source code in <code>src/sst/ml.py</code> <pre><code>def predict_enso_from_sst(\n    df: pd.DataFrame,\n    target_col: str = \"nino34_roll_12\",\n    feature_col: str = \"sst_c_roll_12\",\n    test_size: float = 0.2,\n    n_lags: int = 3,\n    random_state: int = 42,\n    model_path: Path | None = None,\n) -&gt; dict[str, float | pd.DataFrame | RandomForestRegressor]:\n    \"\"\"Predict ENSO index from SST using a Random Forest model with lag features.\n\n    This function creates a machine learning model to predict ENSO (Ni\u00f1o 3.4 index)\n    from sea surface temperature data. It includes lag features to capture temporal\n    dependencies in the time series.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Joined SST and ENSO tidy data that contains a ``date`` column along\n        with at least one rolling SST column and one rolling ENSO column.\n    target_col : str, default=\"nino34_roll_12\"\n        Name of the ENSO column to predict.\n    feature_col : str, default=\"sst_c_roll_12\"\n        Name of the SST column to use as the primary feature.\n    test_size : float, default=0.2\n        Proportion of data to use for testing (between 0 and 1).\n    n_lags : int, default=3\n        Number of lag features to include (previous months' values).\n    random_state : int, default=42\n        Random seed for reproducibility.\n    model_path : pathlib.Path, optional\n        If provided, save the trained model to this path using joblib.\n\n    Returns\n    -------\n    dict[str, float | pandas.DataFrame | RandomForestRegressor]\n        Dictionary containing:\n        - ``r2_score``: R\u00b2 score on test set\n        - ``rmse``: Root mean squared error on test set\n        - ``predictions``: DataFrame with date, actual, and predicted values\n        - ``feature_importance``: DataFrame with feature importance scores\n        - ``model``: Trained RandomForestRegressor model (if model_path provided)\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; from sst.transform import join_on_month, tidy\n    &gt;&gt;&gt; from sst.io import load_sst, load_enso\n    &gt;&gt;&gt; sst_df = tidy(load_sst(\"data/sst_sample.csv\"), \"date\", \"sst_c\")\n    &gt;&gt;&gt; enso_df = tidy(load_enso(\"data/nino34_sample.csv\"), \"date\", \"nino34\")\n    &gt;&gt;&gt; joined = join_on_month(sst_df, enso_df)\n    &gt;&gt;&gt; results = predict_enso_from_sst(joined, model_path=Path(\"model.joblib\"))\n    &gt;&gt;&gt; \"r2_score\" in results\n    True\n    \"\"\"\n    # Prepare the data for training\n    X, y, data, feature_names = _prep_data(df, target_col, feature_col, n_lags)\n\n    # Split into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=test_size, random_state=random_state, shuffle=False\n    )\n\n    # Train Random Forest model\n    model = RandomForestRegressor(n_estimators=100, random_state=random_state, max_depth=10)\n    model.fit(X_train, y_train)\n\n    # Save model if path provided\n    if model_path is not None:\n        dump(model, model_path)\n        result_dict = {\"model\": model}\n    else:\n        result_dict = {}\n\n    # Make predictions\n    _ = model.predict(X_train)\n    y_pred_test = model.predict(X_test)\n\n    # Calculate metrics\n    result_dict.update(_collect_results(model, y_pred_test, y_test, data, feature_names))\n    return result_dict\n</code></pre>"},{"location":"api/plot/","title":"<code>sst.plot</code>","text":"<p>Plotting utilities for SST and ENSO trend visualizations.</p>"},{"location":"api/plot/#sst.plot.make_ml_prediction_plot","title":"<code>make_ml_prediction_plot(results)</code>","text":"<p>Visualize machine learning prediction results for ENSO from SST.</p> <p>Creates a multi-panel figure showing: 1. Time series of actual vs predicted ENSO values 2. Scatter plot of actual vs predicted values 3. Feature importance bar plot</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict[str, float | DataFrame]</code> <p>Dictionary returned by :func:<code>sst.ml.predict_enso_from_sst</code> containing: - <code>predictions</code>: DataFrame with date, actual, predicted, residual columns - <code>feature_importance</code>: DataFrame with feature and importance columns - <code>r2_score</code>: R\u00b2 score (float) - <code>rmse</code>: Root mean squared error (float)</p> required <p>Returns:</p> Type Description <code>Figure</code> <p>Figure with three subplots showing prediction results.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sst.ml import predict_enso_from_sst\n&gt;&gt;&gt; from sst.transform import join_on_month, tidy\n&gt;&gt;&gt; from sst.io import load_sst, load_enso\n&gt;&gt;&gt; sst_df = tidy(load_sst(\"data/sst_sample.csv\"), \"date\", \"sst_c\")\n&gt;&gt;&gt; enso_df = tidy(load_enso(\"data/nino34_sample.csv\"), \"date\", \"nino34\")\n&gt;&gt;&gt; joined = join_on_month(sst_df, enso_df)\n&gt;&gt;&gt; results = predict_enso_from_sst(joined)\n&gt;&gt;&gt; fig = make_ml_prediction_plot(results)\n&gt;&gt;&gt; fig.savefig(\"ml_predictions.png\")\n</code></pre> Source code in <code>src/sst/plot.py</code> <pre><code>def make_ml_prediction_plot(results: dict[str, float | pd.DataFrame]) -&gt; plt.Figure:\n    \"\"\"Visualize machine learning prediction results for ENSO from SST.\n\n    Creates a multi-panel figure showing:\n    1. Time series of actual vs predicted ENSO values\n    2. Scatter plot of actual vs predicted values\n    3. Feature importance bar plot\n\n    Parameters\n    ----------\n    results : dict[str, float | pandas.DataFrame]\n        Dictionary returned by :func:`sst.ml.predict_enso_from_sst` containing:\n        - ``predictions``: DataFrame with date, actual, predicted, residual columns\n        - ``feature_importance``: DataFrame with feature and importance columns\n        - ``r2_score``: R\u00b2 score (float)\n        - ``rmse``: Root mean squared error (float)\n\n    Returns\n    -------\n    matplotlib.figure.Figure\n        Figure with three subplots showing prediction results.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from sst.ml import predict_enso_from_sst\n    &gt;&gt;&gt; from sst.transform import join_on_month, tidy\n    &gt;&gt;&gt; from sst.io import load_sst, load_enso\n    &gt;&gt;&gt; sst_df = tidy(load_sst(\"data/sst_sample.csv\"), \"date\", \"sst_c\")\n    &gt;&gt;&gt; enso_df = tidy(load_enso(\"data/nino34_sample.csv\"), \"date\", \"nino34\")\n    &gt;&gt;&gt; joined = join_on_month(sst_df, enso_df)\n    &gt;&gt;&gt; results = predict_enso_from_sst(joined)\n    &gt;&gt;&gt; fig = make_ml_prediction_plot(results)\n    &gt;&gt;&gt; fig.savefig(\"ml_predictions.png\")\n    \"\"\"\n    predictions_df = results[\"predictions\"]\n    importance_df = results[\"feature_importance\"]\n    r2_score_val = results[\"r2_score\"]\n    rmse_val = results[\"rmse\"]\n\n    # Type assertions for mypy\n    assert isinstance(predictions_df, pd.DataFrame), \"predictions must be a DataFrame\"\n    assert isinstance(importance_df, pd.DataFrame), \"feature_importance must be a DataFrame\"\n    assert isinstance(r2_score_val, float), \"r2_score must be a float\"\n    assert isinstance(rmse_val, float), \"rmse must be a float\"\n\n    r2_score: float = r2_score_val\n    rmse: float = rmse_val\n\n    sns.set_theme(style=\"whitegrid\")\n    fig = plt.figure(figsize=(14, 5))\n\n    # Panel 1: Time series of actual vs predicted\n    ax1 = plt.subplot(1, 3, 1)\n    _plot_ax_1(ax1, predictions_df, r2_score, rmse)\n\n    # Panel 2: Scatter plot of actual vs predicted\n    ax2 = plt.subplot(1, 3, 2)\n    _plot_ax_2(ax2, predictions_df)\n\n    # Panel 3: Feature importance\n    ax3 = plt.subplot(1, 3, 3)\n    _plot_ax_3(ax3, importance_df)\n\n    plt.tight_layout()\n    return fig\n</code></pre>"},{"location":"api/transform/","title":"<code>sst.transform</code>","text":"<p>Transform utilities for preparing SST and ENSO time series.</p>"},{"location":"api/transform/#sst.transform.join_on_month","title":"<code>join_on_month(sst, enso, start=None)</code>","text":"<p>Join SST and ENSO records on their monthly <code>date</code> column.</p> <p>Parameters:</p> Name Type Description Default <code>sst</code> <code>DataFrame</code> <p>Sea surface temperature observations produced by :func:<code>tidy</code>.</p> required <code>enso</code> <code>DataFrame</code> <p>ENSO index observations produced by :func:<code>tidy</code>.</p> required <code>start</code> <code>str</code> <p>Earliest date to retain after joining (inclusive). Parsed with :func:<code>pandas.to_datetime</code> if provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the merged records, filtered to <code>start</code> when supplied, and indexed consecutively.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; sst = tidy(pd.DataFrame({\"date\": [\"2000-01-01\"], \"sst_c\": [20.0]}), \"date\", \"sst_c\")\n&gt;&gt;&gt; enso = tidy(pd.DataFrame({\"date\": [\"2000-01-01\"], \"nino34\": [0.5]}), \"date\", \"nino34\")\n&gt;&gt;&gt; join_on_month(sst, enso).columns.tolist()\n['date', 'sst_c', 'sst_c_roll12', 'nino34', 'nino34_roll12']\n</code></pre> Source code in <code>src/sst/transform.py</code> <pre><code>def join_on_month(sst: pd.DataFrame, enso: pd.DataFrame, start: str | None = None) -&gt; pd.DataFrame:\n    \"\"\"Join SST and ENSO records on their monthly ``date`` column.\n\n    Parameters\n    ----------\n    sst : pandas.DataFrame\n        Sea surface temperature observations produced by :func:`tidy`.\n    enso : pandas.DataFrame\n        ENSO index observations produced by :func:`tidy`.\n    start : str, optional\n        Earliest date to retain after joining (inclusive). Parsed with\n        :func:`pandas.to_datetime` if provided.\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame containing the merged records, filtered to ``start`` when\n        supplied, and indexed consecutively.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; sst = tidy(pd.DataFrame({\"date\": [\"2000-01-01\"], \"sst_c\": [20.0]}), \"date\", \"sst_c\")\n    &gt;&gt;&gt; enso = tidy(pd.DataFrame({\"date\": [\"2000-01-01\"], \"nino34\": [0.5]}), \"date\", \"nino34\")\n    &gt;&gt;&gt; join_on_month(sst, enso).columns.tolist()\n    ['date', 'sst_c', 'sst_c_roll12', 'nino34', 'nino34_roll12']\n    \"\"\"\n\n    df = pd.merge(sst, enso, on=\"date\", how=\"left\")\n    if start:\n        df = df[df[\"date\"] &gt;= pd.to_datetime(start)]\n    return df.reset_index(drop=True)\n</code></pre>"},{"location":"api/transform/#sst.transform.tidy","title":"<code>tidy(df, date_col, value_col, roll=12)</code>","text":"<p>Create a tidy, chronologically ordered DataFrame with rolling means.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Raw input data containing at least the date and value columns.</p> required <code>date_col</code> <code>str</code> <p>Name of the column with dates parsable by :func:<code>pandas.to_datetime</code>.</p> required <code>value_col</code> <code>str</code> <p>Name of the column with the measurement to smooth.</p> required <code>roll</code> <code>int</code> <p>Rolling window size (number of observations) used to compute the mean.</p> <code>12</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Sorted copy of the original data with a new column containing the rolling mean named <code>\"{value_col}_roll_{roll}\"</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; raw = pd.DataFrame({\"date\": [\"2000-01-01\", \"2000-02-01\"], \"sst_c\": [20.0, 20.1]})\n&gt;&gt;&gt; tidy(raw, \"date\", \"sst_c\").columns.tolist()\n['date', 'sst_c', 'sst_c_roll12']\n</code></pre> Source code in <code>src/sst/transform.py</code> <pre><code>def tidy(df: pd.DataFrame, date_col: str, value_col: str, roll: int = 12) -&gt; pd.DataFrame:\n    \"\"\"Create a tidy, chronologically ordered DataFrame with rolling means.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Raw input data containing at least the date and value columns.\n    date_col : str\n        Name of the column with dates parsable by :func:`pandas.to_datetime`.\n    value_col : str\n        Name of the column with the measurement to smooth.\n    roll : int, default=12\n        Rolling window size (number of observations) used to compute the mean.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Sorted copy of the original data with a new column containing the\n        rolling mean named ``\"{value_col}_roll_{roll}\"``.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; raw = pd.DataFrame({\"date\": [\"2000-01-01\", \"2000-02-01\"], \"sst_c\": [20.0, 20.1]})\n    &gt;&gt;&gt; tidy(raw, \"date\", \"sst_c\").columns.tolist()\n    ['date', 'sst_c', 'sst_c_roll12']\n    \"\"\"\n\n    out = df[[date_col, value_col]].copy()\n\n    out[date_col] = pd.to_datetime(out[date_col])\n    out = out.sort_values(date_col).dropna()\n\n    out[f\"{value_col}_roll_{roll}\"] = out[value_col].rolling(roll, min_periods=1).mean()\n    return out\n</code></pre>"}]}